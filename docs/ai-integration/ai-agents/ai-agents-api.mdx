---
title: "AI agents: API"
hide_table_of_contents: true
sidebar_label: AI Agent API
sidebar_position: 0
---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import LanguageSwitcher from "@site/src/components/LanguageSwitcher";
import LanguageContent from "@site/src/components/LanguageContent";

# AI agents: API
<Admonition type="note" title="Note">

* A RavenDB **AI Agent** can be used by a RavenDB client to invoke a chat or 
  a continuous conversation between the client, an AI model, and a RavenDB database.  

* The AI agent can provide the AI model with a set of query and action tools that 
  the LLM can use freely to access the database or trigger the user to action.  

* In this article:
   * [Creating a connection string](../../ai-integration/ai-agents/ai-agents-api.mdx#creating-a-connection-string)  
   * [Defining and running an AI agent](../..ai-integration/ai-agents/ai-agents-api.mdx#defining-and-running-an-ai-agent)
      * [Define agent configuration](../../ai-integration/ai-agents/ai-agents-api.mdx#define-agent-configuration)
      * [Set Agent ID](../../ai-integration/ai-agents/ai-agents-api.mdx#set-agent-id)
      * [Add agent parameters](../../ai-integration/ai-agents/ai-agents-api.mdx#add-agent-parameters)
      * [Set maximum number of iterations](../../ai-integration/ai-agents/ai-agents-api.mdx#set-maximum-number-of-iterations)
      * [Set chat trimming configuration](../../ai-integration/ai-agents/ai-agents-api.mdx#set-chat-trimming-configuration)
      * [Add Sample object or Schema](../../ai-integration/ai-agents/ai-agents-api.mdx#add-sample-object-or-schema)
      * [Add agent tools](../../ai-integration/ai-agents/ai-agents-api.mdx#add-sample-object-or-schema)
         * [Query tools](../../ai-integration/ai-agents/ai-agents-api.mdx#query-tools)
         * [Action tools](../../ai-integration/ai-agents/ai-agents-api.mdx#query-tools)
      * [Create the agent](../../ai-integration/ai-agents/ai-agents-api.mdx#query-tools)
   * [Conversations](../../ai-integration/ai-agents/ai-agents-api.mdx#conversations)
      * [Chats](../../ai-integration/ai-agents/ai-agents-api.mdx#chats)
      * [Continuous conversations](../../ai-integration/ai-agents/ai-agents-api.mdx#chats)
      * [Stored conversations' Prefix and IDs](../../ai-integration/ai-agents/ai-agents-api.mdx#stored-conversations-prefix-and-ids)
      * [Set and start the chat](../../ai-integration/ai-agents/ai-agents-api.mdx#set-and-start-the-chat)
      * [Chat reply](../../ai-integration/ai-agents/ai-agents-api.mdx#chat-reply)
   * [Full Example](../../ai-integration/ai-agents/ai-agents-api.mdx#full-example)
</Admonition>
## Creating a connection string

Your agent will need a connection string to connect with the LLM. Create a connection string 
using an `AiConnectionString` instance and the `PutConnectionStringOperation` operation.  
(You can also create a connection string using Studio, see [here](../../ai-integration/ai-agents/ai-agents-studio.mdx#configure-basic-settings))

You can use a local `Ollama` model if your considerations are mainly speed, cost, open-source, or security,  
Or you can use a remote `OpenAI` service for its additional resources and capabilities.  
### Example:

<Tabs groupId='languageSyntax'>
<TabItem value="open-ai-cs" label="open-ai-cs">
<CodeBlock language="csharp">
{`using (var store = new DocumentStore())
{
    // Define the connection string to OpenAI
    var connectionString = new AiConnectionString
    {
        // Connection string name & identifier
        Name = "open-ai-cs",

        // OpenAI connection settings
        OpenAiSettings = new OpenAiSettings(
            apiKey: "your-api-key",
            endpoint: "https://api.openai.com/v1",
            // LLM model for text generation
            model: "gpt-4.1")
    };

    // Deploy the connection string to the server
    var operation = new PutConnectionStringOperation<AiConnectionString>(connectionString);
    var putConnectionStringResult = store.Maintenance.Send(operation);
}
`}
</CodeBlock>
</TabItem>
<TabItem value="ollama-cs" label="ollama-cs">
<CodeBlock language="csharp">
{`using (var store = new DocumentStore())
{
    // Define the connection string to Ollama
    var connectionString = new AiConnectionString
    {
        // Connection string name & identifier
        Name = "ollama-cs",

        // Ollama connection settings
        OllamaSettings = new OllamaSettings(
            // LLM Ollama model for text generation
            model: "llama3.2",
            // local URL
            uri: "http://localhost:11434/")
    };

    // Deploy the connection string to the server
    var operation = new PutConnectionStringOperation<AiConnectionString>(connectionString);
    var putConnectionStringResult = store.Maintenance.Send(operation);
}
`}
</CodeBlock>
</TabItem>
</Tabs>
### Syntax:

<Tabs groupId='languageSyntax'>
<TabItem value="open-ai-cs-syntax" label="open-ai-cs-syntax">
<CodeBlock language="csharp">
{`public class AiConnectionString
{
    public string Name { get; set; }
    public string Identifier { get; set; }
    public OpenAiSettings OpenAiSettings { get; set; }
    ...
}

public class OpenAiSettings : AbstractAiSettings
{
    public string ApiKey { get; set; }
    public string Endpoint { get; set; }
    public string Model { get; set; }
    public int? Dimensions { get; set; }
    public string OrganizationId { get; set; }
    public string ProjectId { get; set; }
}
`}
</CodeBlock>
</TabItem>
<TabItem value="ollama-cs-syntax" label="ollama-cs-syntax">
<CodeBlock language="csharp">
{`public class AiConnectionString
{
    public string Name { get; set; }
    public string Identifier { get; set; }
    public OllamaSettings OllamaSettings { get; set; }
    ...
}

public class OllamaSettings : AbstractAiSettings
{
    public string Model { get; set; }
    public string Uri { get; set; }
}
`}
</CodeBlock>
</TabItem>
</Tabs>



## Defining and running an AI agent

## Define agent configuration

To create an AI agent you need to prepare an **agent configuration** and populate it with 
your settings and tools.  

Start by creating a new `AiAgentConfiguration` instance.  
While creating the instance, pass its constructor:  

- The agent's Name  
- The [connection string](../../ai-integration/ai-agents/ai-agents-api.mdx#creating-a-connection-string) you created  
- A System prompt  

The agent will send the system prompt you define here to the LLM, to define the LLM's role 
and explain it how this role should be fulfilled.  

In the following example we create a system prompt that assigns the LLM the role of a helper 
to a human experience manager, who wants to reward the employee who made the biggest profit.

The LLM will retrieve from the Orders collection the IDs of employees and the sums they made 
for each order, to find which employee has made the biggest profit. Then, the LLM will retrieve 
additional information about this employee from the database and suggest the manager a reward.  

We are very careful and selective with the details we send the LLM about employees and orders.  

<TabItem value="ai-agents_AiAgentConfiguration_example" label="ai-agents_AiAgentConfiguration_example">
<CodeBlock language="csharp">
{`// Agent configuration
var agent = new AiAgentConfiguration("congratulate-employee-with-present", connectionString.Name,
    "You work for a human experience manager. " +
    "The manager uses your help to find which employee made the largest profit and thank this employee. " +
    "The manager can guide you to choose between employees that sent orders to a particular country, " +
    "or include all employees." +
    "To help the manager thank the employee, you are requested to find good vacation sites or other presents " +
    "based on the employee's living area that the company can reward them with. " +
    "You are equipped with: " +
    "1. a query tool that allows you to retrieve all orders sent to all countries. use this tool to retrieve " +
    "orders and calculate which employee made the largest profit. " +
    "2. A query tool that allows you to retrieve all the orders sent to a particular country. use this tool " +
    "if the user prompt specifies a country, and calculate which employee that sent products to this country " +
    "made the largest profit. " +
    "3.An action tool that you can provide the employee's ID with to get the employee's living region." +
    "When you're done, return the employee ID, the profit the employee made, and the suggested rewards."
    );
`}
</CodeBlock>
</TabItem>

* Method definition:  
<TabItem value="ai-agents_AiAgentConfiguration_definition" label="ai-agents_AiAgentConfiguration_definition">
<CodeBlock language="csharp">
{`public AiAgentConfiguration(string name, string connectionStringName, string systemPrompt);
`}
</CodeBlock>
</TabItem>

* `AiAgentConfiguration` definition:
<TabItem value="ai-agents_AiAgentConfiguration-class_definition" label="ai-agents_AiAgentConfiguration-class_definition">
<CodeBlock language="csharp">
{`public class AiAgentConfiguration
\{
    // A unique identifier given to the AI agent configuration
    public string Identifier \{ get; set; \}

    // The name of the AI agent configuration
    public string Name \{ get; set; \}

    // Connection string name
    public string ConnectionStringName \{ get; set; \}

    // The system promnpt that defines the role and purpose of the agent and the LLM
    public string SystemPrompt \{ get; set; \}

    // An example object that sets the layout for the LLM's response to the user.
    // The object is translated to a schema before we send it to the LLM.
    public string SampleObject \{ get; set; \}

    // A schema that sets the layout for the LLM's response to the user.
    // If both a sample object and a schema are defined, only the schema is used.
    public string OutputSchema \{ get; set; \}

    // A list of Query tools that the LLM can use (through the agent) to access the database
    public List<AiAgentToolQuery> Queries \{ get; set; \} = new List<AiAgentToolQuery>();

    // A list of Action tools that the LLM can use to trigger the user to action
    public List<AiAgentToolAction> Actions \{ get; set; \} = new List<AiAgentToolAction>();

    // Agent parameters whose value the client passes to the LLM each time a chat is started, 
    // for stricter control over queris initiated by the LLM and as a means for interaction 
    // between the client and the LLM.  
    public List<AiAgentParameter> Parameters \{ get; set; \} = new List<AiAgentParameter>();

    // The trimming configuration defines if and how the chat history is summarized, 
    // to minimize the amount of data passed to the LLM when a chat is started.  
    public AiAgentChatTrimmingConfiguration ChatTrimming \{ get; set; \} = new AiAgentChatTrimmingConfiguration(new AiAgentSummarizationByTokens());
    
    // Control over the number of times that the LLMis allowed to use agent tools to handle a user prompt.  
    public int? MaxModelIterationsPerCall \{ get; set; \}
\}
`}
</CodeBlock>
</TabItem>
Once the agent configuration is created, we need to add it a few additional elements.  

## Set agent ID

Use the `Identifier` property to provide the agent with a unique ID that the 
system will recognize it by.  
<TabItem value="ai-agents_agent-identifier" label="ai-agents_agent-identifier">
<CodeBlock language="csharp">
{`// Agent ID
agent.Identifier = "congratulate-employee-with-present";
`}
</CodeBlock>
</TabItem>

## Add agent parameters

Agent parameters are optional variables, whose values are provided by the client 
(or by a user through the client) to the agent when a chat is started.  
The values are then embedded by the client in query tools, and used when these 
tools are applied. Users and clients can provide their selections and preferences 
using agent parameters when the chat starts, and focus the queries and the whole 
interaction on their selections.  

In the example shown below, for example, an agent parameter is used to determine 
what area of the world a query will handle. Another example can be a student that 
uses a librarian agent, providing the agent with a subject and having the agent 
fetch and summarize documents related to this subject.  

To add an agent parameter create an `AiAgentParameter` instance, initialize it with 
the parameter's **name** and **description** (explaining the LLM what the parameter 
is for), and pass this instance to the `agent.Parameters.Add` method.  

* Example:
<TabItem value="ai-agents_AiAgentParameter_function" label="ai-agents_AiAgentParameter_function">
<CodeBlock language="csharp">
{`//  Agent parametera
agent.Parameters.Add(new AiAgentParameter("country", "A specific country that orders were shipped to, or \\"everywhere\\" to look for orders shipped to all countries"));
`}
</CodeBlock>
</TabItem>

* `AiAgentParameter` Definition:
<TabItem value="ai-agents_AiAgentParameter_definition" label="ai-agents_AiAgentParameter_definition">
<CodeBlock language="csharp">
{`public AiAgentParameter(string name, string description);
`}
</CodeBlock>
</TabItem>

## Set maximum number of iterations

You can limit the number of times that the LLM is allowed to request the usage of 
agent tools in response to a single user prompt.  
To change this limit use `MaxModelIterationsPerCall`.  

* Example:
<TabItem value="ai-agents_MaxModelIterationsPerCall_function" label="ai-agents_MaxModelIterationsPerCall_function">
<CodeBlock language="csharp">
{`// Limit the number of times the LLM can request for tools in response to a single user prompt
agent.MaxModelIterationsPerCall = 3;
`}
</CodeBlock>
</TabItem>

* `AiAgentParameter` Definition:
<TabItem value="ai-agents_MaxModelIterationsPerCall_definition" label="ai-agents_MaxModelIterationsPerCall_definition">
<CodeBlock language="csharp">
{`public int? MaxModelIterationsPerCall
`}
</CodeBlock>
</TabItem>

## Set chat trimming configuration

Since the LLM keeps no history of previous chats, we include in every new message we send 
it the entire conversation from its start.  
To save traffic and tokens, you can summarize older messages.  
This can be helpful when transfer rate and cost are a concern or the context may become 
too large to handle efficiently.  

To summarize old messages create an `AiAgentChatTrimmingConfiguration` instance, 
use this instance to configure your trimming strategy, and set the agent's `ChatTrimming` property 
with the instance.  

When creating the instance, pass its constructor a summarization strategy using 
a `AiAgentSummarizationByTokens` class.  

A history of the original messages, before they were summarized, can optionally be 
kept in the `@conversations-history` collection.  
To determine whether to keep the original messages and for how long, also pass the 
`AiAgentChatTrimmingConfiguration` constructor an `AiAgentHistoryConfiguration` instance 
with your history settings.  

* Example:
<TabItem value="ai-agents_trimming-configuration_example" label="ai-agents_trimming-configuration_example">
<CodeBlock language="csharp">
{`// Set chat trimming configuration
AiAgentSummarizationByTokens summarization = new AiAgentSummarizationByTokens()
\{
    SummarizationTaskBeginningPrompt = "Summarize the conversation so far.",
    SummarizationTaskEndPrompt = "Generate a summary of the conversation.",
    ResultPrefix = "Summary: ",
    MaxTokensBeforeSummarization = 10000,
    MaxTokensAfterSummarization = 10000
\};

AiAgentHistoryConfiguration history = new AiAgentHistoryConfiguration()
\{
    HistoryExpirationInSec = 60 * 60 * 24 // 1 day
\};

agent.ChatTrimming = new AiAgentChatTrimmingConfiguration(summarization, history);
`}
</CodeBlock>
</TabItem>

* Syntax:
<TabItem value="ai-agents_trimming-configuration_syntax" label="ai-agents_trimming-configuration_syntax">
<CodeBlock language="csharp">
{`public class AiAgentSummarizationByTokens
\{
    // Sent with the system prompt and appears before any summary content.
    // Customize it to influence the structure, tone, or depth of the generated summary.
    public string SummarizationTaskBeginningPrompt \{ get; set; \}

    // A concise request to generate the summary according to the guidelines set by 
    // SummarizationTaskBeginningPrompt. Sent after the system prompt.
    // Adjust its phrasing to change how explicitly the model understands the summarization task.
    public string SummarizationTaskEndPrompt \{ get; set; \}

    // An introductory prefix that appears before the generated summary of the previous conversation.
    // Customize this prefix to change how the summary is introduced when producing conversation summaries.
    public string ResultPrefix \{ get; set; \}

    // The maximum number of tokens allowed before summarization is triggered.
    public long? MaxTokensBeforeSummarization \{ get; set; \}

    // The maximum number of tokens allowed in the generated summary.
    public long? MaxTokensAfterSummarization \{ get; set; \}
\}
*/

/*
public class AiAgentHistoryConfiguration
\{
    // Enables history for the AI agents conversations.
    public AiAgentHistoryConfiguration()

    // Enables history for the AI agents conversations.
    // <param name="expiration">The timespan after which history documents expire.</param>
    public AiAgentHistoryConfiguration(TimeSpan expiration)

    // The timespan after which history documents expire.
    public int? HistoryExpirationInSec \{ get; set; \}
\}
`}
</CodeBlock>
</TabItem>


## Add Sample object or Schema

At the end of a chat, when the LLM is done processing and negotiating, 
it returns a structured output reply through the agent to the client in an 
object whose layout we need to prepare beforehand.  
The layout object we prepare is sent to the LLM when the agent is started.  

You can prepare this object in two different formats.  
The first format is the formal **JSON-based schema** in which the LLM expects 
the structure to arrive.  
The second is a friendlier **sample object** format, that RavenDB will turn 
to a schema behind the scenes for us.  
Normally the simpler way is to prepare a sample object and let RavenDB translate 
it to a schema for you.  

If you prepare both a sample object and a schema, the schema will be used.  

Example:
<Tabs groupId='languageSyntax'>
<TabItem value="sample-object" label="sample-object">
<CodeBlock language="json">
{`{
    "DocumentName": "The document's original title",
    "DocumentSummary": "The summarized document"
}
`}
</CodeBlock>
</TabItem>
<TabItem value="schema" label="schema">
<CodeBlock language="json">
{`{
  "name": "QSt6RSthRGQ5OEVhNTBETTJSOHhUaWc5VDRocXV6MjM0OU85M2tJYnhMbz0",
  "strict": true,
  "schema": {
    "type": "object",
    "properties": {
      "DocumentName": {
        "type": "string",
        "description": "The document\\u0027s original title"
      },
      "DocumentSummary": {
        "type": "string",
        "description": "The summarized document"
      }
    },
    "required": [
      "DocumentName",
      "DocumentSummary"
    ],
    "additionalProperties": false
  }
}
`}
</CodeBlock>
</TabItem>
</Tabs>

To prepare a sample object, use the agent's `SampleObject` string property.  
To prepare a schema, use `OutputSchema`.  
<TabItem value="ai-agents_agent_sampleObjectString" label="ai-agents_agent_sampleObjectString">
<CodeBlock language="csharp">
{`// Set sample object
agent.SampleObject = "\{" +
                        "\\"EmployeeID\\": \\"embed the employee’s ID here\\"" +
                        "\\"EmployeeProfit\\": \\"embed the profit made by the employee here\\"," +
                        "\\"Suggestions\\": \\"embed suggested rewards here\\"" +
                     "\}";
`}
</CodeBlock>
</TabItem>


## Add agent tools

You can enhance your agent with Query and Action tools, that allow the LLM 
to query your database and trigger client actions.  

After defining agent tools and submitting them to the LLM, it is up to the LLM 
to decide if and when to use them. 

### Query tools

Query tools provide the LLM with the ability to retrieve data from the database.  
Once defined, the LLM can use them of its own accord.  

A query tool includes a a natural-language **description** that explain the LLM what 
the tool is for, and an **RQL query**.  
To use a query tool, the LLM will requests the agent to apply it, and the agent will 
run the query and send the LLM the results.  

The RQL query can include parameters.  
E.g., `where Country == $country`
When these parameters are agent parameters, their values are provided by the user 
when the chat is initiated.  
But a query tool also includes a **tool parameters schema** that defines parameters 
that the LLM can set and request the agent to use in the query.  

You can choose for yourself whether to define the tool parameters schema as 
a **sample object** or **schema**, just be aware that if you define both only 
the schema will be used.  

Query tools are for **read only operations**. To make changes in the database, 
use an action tool.  

* **Example**:  
  The following query tools are used by an agent that helps a human experience manager 
  learn which employee made the largest profit. They use a `$country` agent parameter whose 
  value the manager provides when the chat is started. If the parameter's value is "everywhere" 
  the first tool is applied, and if it is a specific country the second tool is applied.  
  The tools retrieve all the orders that were sent to the selected destination.  
  As instructed in the system prompt, the LLM will then calculate which employee 
  made the largest profit, and send its ID to the user (human experience manager) 
  through an action tool (explained below).  
<TabItem value="ai-agents_agent_query-tool-sample" label="ai-agents_agent_query-tool-sample">
<CodeBlock language="csharp">
{`agent.Queries =
[   
    // Set first query tool
    new AiAgentToolQuery
    \{
        Name = "retrieve-orders-sent-to-all-countries",
        Description = "a query tool that allows you to retrieve all orders sent to all countries.",
        Query = "from \\"Orders\\" " +
                "select Employee, Lines.Quantity",
        ParametersSampleObject = "\{" +
                                    "\\"Employee\\": \\"employee ID\\"," +
                                    "\\"Lines.Quantity\\": \\"an array of profits made by this employee\\"" +
                                 "\}"
    \},
    
    // Set second query tool
    new AiAgentToolQuery
    \{
        Name = "retrieve-orders-sent-to-a-particular-country",
        Description = "a query tool that allows you to retrieve all orders sent to a particular country",
        Query = "from \\"Orders\\" where ShipTo.Country == $country " +
                "select Employee, Lines.Quantity",
        ParametersSampleObject = "\{" +
                                    "\\"Employee\\": \\"employee ID\\"," +
                                    "\\"Lines.Quantity\\": \\"an array of profits made by this employee\\"" +
                                 "\}"
    \}
];
`}
</CodeBlock>
</TabItem>

* **Syntax**:
  Query tools are defined in a list of `AiAgentToolQuery` classes.  
<TabItem value="ai-agents_AiAgentToolQuery_definition" label="ai-agents_AiAgentToolQuery_definition">
<CodeBlock language="csharp">
{`public class AiAgentToolQuery
\{
    public string Name \{ get; set; \}
    public string Description \{ get; set; \}
    public string Query \{ get; set; \}
    public string ParametersSampleObject \{ get; set; \}
    public string ParametersSchema \{ get; set; \}
\}
`}
</CodeBlock>
</TabItem>


### Action tools

Action tools allow the LLM to trigger the client to perform actions like modifying, adding, 
or removing documents.  

Unlike a query tool, an action tool does not include a query. It only includes a description 
and a schema.  
The description informs the LLM in natural language what the tool is capable of.  
The schema is filled by the LLM with values when it requests the agent to apply the action.  

When the LLM sends the agent a request to use an action tool, the chat will halt and 
wait for the agent's response. The agent will perform the action, populate the object 
whose layout is determined by the parameters schema, and reply to the LLM with the response.  

* The following action tool gets from the LLM an ID of an employee and transfers an 
  object with this ID to the client. The client will need to provide an employee's living 
  region and resume the chat with a prompt that includes the requested data.  
  As defined by the system prompt, this data will be used by the LLM to find a vacation 
  or another present for the employee based on its location, in reward for the employee's 
  performance.  
<TabItem value="ai-agents_agent_action-tool-sample" label="ai-agents_agent_action-tool-sample">
<CodeBlock language="csharp">
{`agent.Actions =
[   // set action tool
    new AiAgentToolAction
    \{
        Name = "request-employee-details-by-ID",
        Description = "an action tool that allows you to provide the user the ID of the employee that made " +
                      "the largest profit so the user will send you a prompt with the employee’s living region",
        ParametersSampleObject = "\{" +
                                    "\\"EmployeeID\\": \\"embed the employee’s ID here\\"" +
                                 "\}"
    \}
];
`}
</CodeBlock>
</TabItem>

* Syntax:
  Action tools are defined in a list of `AiAgentToolAction` classes.  
<TabItem value="ai-agents_AiAgentToolAction_definition" label="ai-agents_AiAgentToolAction_definition">
<CodeBlock language="csharp">
{`public class AiAgentToolAction
\{
    public string Name \{ get; set; \}
    public string Description \{ get; set; \}
    public string ParametersSampleObject \{ get; set; \}
    public string ParametersSchema \{ get; set; \}

\}
`}
</CodeBlock>
</TabItem>

## Create the agent

Now that the agent configuration is ready, we can create the agent using the `CreateAgentAsync` operation.  
`CreateAgentAsync` has multiple overloads that we can use, including two that use the return schema defined 
within the agent configuration and one that passes to the method a sample object that will define the schema.  

* Example:  
<TabItem value="ai-agents_CreateAgentAsync_example" label="ai-agents_CreateAgentAsync_example">
<CodeBlock language="csharp">
{`var createResult = await store.AI.CreateAgentAsync(agent);
`}
</CodeBlock>
</TabItem>

* Syntax:  
<TabItem value="ai-agents_CreateAgentAsync_overloads" label="ai-agents_CreateAgentAsync_overloads">
<CodeBlock language="csharp">
{`// Create the agent with just the defined agent configuration
CreateAgentAsync(configuration);

CreateAgentAsync(AiAgentConfiguration configuration, CancellationToken token = default(CancellationToken));

// Create the agent with the agent configuration,         
CreateAgentAsync<TSchema>(AiAgentConfiguration configuration, TSchema sampleObject, CancellationToken token = default(CancellationToken));
`}
</CodeBlock>
</TabItem>



## Conversations

A conversation is a communication session between the client, the agent, and the LLM, 
during which the LLM may use agent tools to interact with the database and the client.  

If [agent parameters](../../ai-integration/ai-agents/ai-agents-api.mdx#add-agent-parameters) 
were defined, the agent will start the conversation only when they are provided.  

### Continuous conversations
The LLM does not record its chats, starting a new chat means losing the chat history.  
The AI agent allows a continuous conversation by storing conversations history in the 
`@conversations` collection. When a new chat starts, it continues where it left off 
because the agent sends the conversation history to the LLM.  

### Stored conversations' Prefix and IDs
Conversations are kept in the `@conversations` collection with a prefix (such as `Chats/`) 
that can be set when the conversation is initiated. The conversation ID that follows the prefix 
is created automatically by RavenDB, similarly to the creation of automatic IDs for documents.  

You can:  

* Provide a full ID  
* Provide a prefix that ends with `/` or `|` to trigger automatic ID creation.  


## Set and start the chat

- Set a chat using the `store.AI.Conversation` method.  
  Pass `Conversation`:  
   - The **agent ID**  
   - The **conversaion ID**  
     If you pass the method the ID of an existing conversation (e.g. `"Chats/0000000000000008883-A"`) 
     the conversation will be retrieved from storage and continued where you left off.  
     If you provide an empty prefix (e.g. `"Chats/`), a new conversation will start.  
   - **agent parameter values** in an `AiConversationCreationOptions` instance.  
- Set the user prompt using the `SetUserPrompt`method.  
  The user prompt informs the agent with the user's requests and expectations for this chat.  
- Use the value returned by the `Conversation` method to run the chat.

### Chat reply

LLM replies are returned by the agent to the client in an `AiAnswer` object.  
The conversation status is indicated by `AiAnswer.AiConversationResult`.   

* `AiAnswer`syntax:
<TabItem value="ai-agents_AiAnswer" label="ai-agents_AiAnswer">
<CodeBlock language="csharp">
{`public class AiAnswer<TAnswer>
\{
    // The answer content produced by the AI
    public TAnswer Answer;

    // The status of the conversation
    public AiConversationResult Status;
\}

public enum AiConversationResult
\{
    // The conversation has completed and a final answer is available
    Done,
    // Further interaction is required, such as responding to tool requests
    ActionRequired
\}
`}
</CodeBlock>
</TabItem>

First, check the conversation status to see if this is the agent's final response 
or whether it just requests the client to apply an action tool.  

- A request for action is relayed by an `AiConversationResult.ActionRequired` status, 
  with any additional details stored in `AiAnswer.Answer` - within the return object 
  that you defined for the action tool.  
  To send requested data to the agent, use `chat.SetUserPrompt` to set the data as 
  the user prompt and use `chat.RunAsync` to resume the chat. The prompt will be sent 
  to the LLM by the agent and the chat will continue.  

- A final response from the LLM is relayed by a `AiConversationResult.Done` status, 
  with the LLM's message stored in `AiAnswer.Answer` - within the return object that 
  you defined for the agent.  

In the example below the chat is initiated with a user prompt and an agent parameter 
from the human experience manager, requesting the LLM to check which employee made 
the largest profit with orders sent to the selected country (or "everywhere" for the 
entire world).  
The reply is then checked:  
If this is an action request, the ID of the highest-grossing employee is retrieved 
from the answer, additional data is retrieved from the database based on this ID, and 
the chat is resumed with the retrieved data as a user prompt.  
If this is the final LLM response, the LLM suggestions regarding a reward for the 
employee are also provided in the answer and can be handled further.  

* Example: 
<TabItem value="ai-agents_Conversation_example" label="ai-agents_Conversation_example">
<CodeBlock language="csharp">
{`// Set chat
var chat = store.AI.Conversation(
    createResult.Identifier,
    "suggestions/",
    new AiConversationCreationOptions().AddParameter("country", "France"));

// Set user prompt and run the chat
chat.SetUserPrompt("check which employee made the largest profit");
var LLMResponse = await chat.RunAsync<OutputSchem>(CancellationToken.None);

Employee employee;
if (LLMResponse.Status == AiConversationResult.ActionRequired)
\{
    // Handle action required case

    // The LLM response indicates that an action is required to fetch the employee's ID
    // Extract the employee ID from the LLM response
    var employeeId = LLMResponse.Answer.EmployeeID;

    employee = (Employee)session.Advanced
        .AsyncDocumentQuery<Employee>()
        .WhereEquals(x => x.Id, employeeId);

    // Run the chat again and send as user prompt the details requested by the LLM
    chat.SetUserPrompt("\{\\"City\\": " + employee.Address.City +
                       "\{\\"Region\\": " + employee.Address.Region +
                       "\{\\"Country\\": " + employee.Address.Country);
    LLMResponse = await chat.RunAsync<OutputSchem>(CancellationToken.None);

    if (LLMResponse.Status == AiConversationResult.Done)
    \{
        // The LLM has successfully processed the action and returned the final response
        // Find it in LLMResponse.Answer.EmployeeID, LLMResponse.Answer.EmployeeProfit, 
        // and LLMResponse.Answer.SuggestedRewards
    \}
\}
`}
</CodeBlock>
</TabItem>

* `Conversation` Definition:  
<TabItem value="ai-agents_Conversation_definition" label="ai-agents_Conversation_definition">
<CodeBlock language="csharp">
{`public IAiConversationOperations Conversation(string agentId, string conversationId, AiConversationCreationOptions creationOptions, string changeVector = null)
`}
</CodeBlock>
</TabItem>

* `SetUserPrompt` Definition:  
<TabItem value="ai-agents_SetUserPrompt_definition" label="ai-agents_SetUserPrompt_definition">
<CodeBlock language="csharp">
{`void SetUserPrompt(string userPrompt);
`}
</CodeBlock>
</TabItem>
  


## Full example

The agent in this example is a library assistant with access to a documentation database.  
Its users pass it a subject, and the agent searches the database for documents in this 
subject by their title. When it finds a document that suits the user it gives the user 
asummary of the document. It uses a query tool to search the documents, and an action 
tool to trigger the user to retrieve for it the text from the document.  

<TabItem value="ai-agents_full-example" label="ai-agents_full-example">
<CodeBlock language="csharp">
{`public async Task FullAIAgentsExample()
\{
    var store = new DocumentStore();

    // Define the connection string to OpenAI
    var connectionString = new AiConnectionString
    \{
        // Connection string name & identifier
        Name = "open-ai-cs",

        // OpenAI connection settings
        OpenAiSettings = new OpenAiSettings(
            apiKey: "your-api-key",
            endpoint: "https://api.openai.com/v1",
            // LLM model for text generation
            model: "gpt-4.1")
    \};

    // Deploy the connection string to the server
    var operation = new PutConnectionStringOperation<AiConnectionString>(connectionString);

    var putConnectionStringResult = store.Maintenance.Send(operation);

    using var session = store.OpenAsyncSession();

    // Agent configuration
    var agent = new AiAgentConfiguration("congratulate-employee-with-present", connectionString.Name,
        "You work for a human experience manager. " +
        "The manager uses your help to find which employee made the largest profit and thank this employee. " +
        "The manager can guide you to choose between employees that sent orders to a particular country, " +
        "or include all employees." +
        "To help the manager thank the employee, you are requested to find good vacation sites or other presents " +
        "based on the employee's living area that the company can reward them with. " +
        "You are equipped with: " +
        "1. a query tool that allows you to retrieve all orders sent to all countries. use this tool to retrieve " +
        "orders and calculate which employee made the largest profit. " +
        "2. A query tool that allows you to retrieve all the orders sent to a particular country. use this tool " +
        "if the user prompt specifies a country, and calculate which employee that sent products to this country " +
        "made the largest profit. " +
        "3.An action tool that you can provide the employee's ID with to get the employee's living region." +
        "When you're done, return the employee ID, the profit the employee made, and the suggested rewards."
        );

    // Agent ID
    agent.Identifier = "congratulate-employee-with-present";

    //  Agent parametera
    agent.Parameters.Add(new AiAgentParameter("country", "A specific country that orders were shipped to, or \\"everywhere\\" to look for orders shipped to all countries"));

    // Set sample object
    agent.SampleObject = "\{" +
                            "\\"EmployeeID\\": \\"embed the employee’s ID here\\"" +
                            "\\"EmployeeProfit\\": \\"embed the profit made by the employee here\\"," +
                            "\\"Suggestions\\": \\"embed suggested rewards here\\"" +
                         "\}";

    agent.Queries =
    [   
        // Set first query tool
        new AiAgentToolQuery
        \{
            Name = "retrieve-orders-sent-to-all-countries",
            Description = "a query tool that allows you to retrieve all orders sent to all countries.",
            Query = "from \\"Orders\\" " +
                    "select Employee, Lines.Quantity",
            ParametersSampleObject = "\{" +
                                        "\\"Employee\\": \\"employee ID\\"," +
                                        "\\"Lines.Quantity\\": \\"an array of profits made by this employee\\"" +
                                     "\}"
        \},
        
        // Set second query tool
        new AiAgentToolQuery
        \{
            Name = "retrieve-orders-sent-to-a-particular-country",
            Description = "a query tool that allows you to retrieve all orders sent to a particular country",
            Query = "from \\"Orders\\" where ShipTo.Country == $country " +
                    "select Employee, Lines.Quantity",
            ParametersSampleObject = "\{" +
                                        "\\"Employee\\": \\"employee ID\\"," +
                                        "\\"Lines.Quantity\\": \\"an array of profits made by this employee\\"" +
                                     "\}"
        \}
    ];

    agent.Actions =
    [   
        // set action tool
        new AiAgentToolAction
        \{
            Name = "request-employee-details-by-ID",
            Description = "an action tool that allows you to provide the user the ID of the employee that made " +
                          "the largest profit so the user will send you a prompt with the employee’s living region",
            ParametersSampleObject = "\{" +
                                        "\\"EmployeeID\\": \\"embed the employee’s ID here\\"" +
                                     "\}"
        \}
    ];

    // Set chat trimming configuration
    AiAgentSummarizationByTokens summarization = new AiAgentSummarizationByTokens()
    \{
        SummarizationTaskBeginningPrompt = "Summarize the conversation so far.",
        SummarizationTaskEndPrompt = "Generate a summary of the conversation.",
        ResultPrefix = "Summary: ",
        MaxTokensBeforeSummarization = 10000,
        MaxTokensAfterSummarization = 10000
    \};
    agent.ChatTrimming = new AiAgentChatTrimmingConfiguration(summarization);

    // Limit the number of times the LLM can request for tools in response to a single user prompt
    agent.MaxModelIterationsPerCall = 3;

    var createResult = await store.AI.CreateAgentAsync(agent);
    // Set chat
    var chat = store.AI.Conversation(
        createResult.Identifier,
        "suggestions/",
        new AiConversationCreationOptions().AddParameter("country", "France"));

    // Set user prompt and run the chat
    chat.SetUserPrompt("check which employee made the largest profit");
    var LLMResponse = await chat.RunAsync<OutputSchem>(CancellationToken.None);

    Employee employee;
    if (LLMResponse.Status == AiConversationResult.ActionRequired)
    \{
        // Handle action required case

        // The LLM response indicates that an action is required to fetch the employee's ID
        // Extract the employee ID from the LLM response
        var employeeId = LLMResponse.Answer.EmployeeID;

        employee = (Employee)session.Advanced
            .AsyncDocumentQuery<Employee>()
            .WhereEquals(x => x.Id, employeeId);

        // Run the chat again and send as user prompt the details requested by the LLM
        chat.SetUserPrompt("\{\\"City\\": " + employee.Address.City +
                           "\{\\"Region\\": " + employee.Address.Region +
                           "\{\\"Country\\": " + employee.Address.Country);
        LLMResponse = await chat.RunAsync<OutputSchem>(CancellationToken.None);

        if (LLMResponse.Status == AiConversationResult.Done)
        \{
            // The LLM has successfully processed the action and returned the final response
            // Find it in LLMResponse.Answer.EmployeeID, LLMResponse.Answer.EmployeeProfit, 
            // and LLMResponse.Answer.SuggestedRewards
        \}
    \}
\}

public class OutputSchem
\{
    public static OutputSchem Instance = new();
    public string EmployeeID = "The employee's ID";
    public string EmployeeProfit = "The profit made by the employee";
    public string SuggestedRewards = "Suggested rewards for the employee";
\}
`}
</CodeBlock>
</TabItem>



