import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

Pending session operations e.g. `store()`, `delete()` and many others will not be send to server until `saveChanges()` is called.

## Syntax

<TabItem value="saving_changes_1" label="saving_changes_1">
<CodeBlock language="js">
{`session.saveChanges();
`}
</CodeBlock>
</TabItem>

| Parameters | | |
| ------------- | ------------- | ----- |
| **callback** | function | (optional) A function called once session changes are persisted to the server |


| Return Value | |
| ------------- | ----- |
| `Promise` | A `Promise` resolved once session changes are persisted to the server |

### Example

<TabItem value="saving_changes_2" label="saving_changes_2">
<CodeBlock language="js">
{`const employee = new Employee("John", "Doe");
await session.store(employee);
await session.saveChanges();
`}
</CodeBlock>
</TabItem>

## Waiting for Indexes

You can ask the server to wait until the indexes are caught up with changes made within the current session before the `saveChanges()` returns.

* You can set a timeout (default: 15 seconds).
* You can specify whether you want to throw on timeout (default: `false`).
* You can specify indexes that you want to wait for. If you don't specify anything here, RavenDB will automatically select just the indexes that are impacted 
by this write.

<TabItem value="saving_changes_3" label="saving_changes_3">
<CodeBlock language="js">
{`session.advanced.waitForIndexesAfterSaveChanges(\{
    indexes: ["index/1", "index/2"],
    throwOnTimeout: true,
    timeout: 30 * 1000 // 30 seconds in ms
\});

const employee = new Employee("John", "Doe");
await session.store(employee);
await session.saveChanges();
`}
</CodeBlock>
</TabItem>



## Waiting for Replication - Write Assurance

Sometimes you might need to ensure that changes made in the session will be replicated to more than one node of the cluster before the `saveChanges()` returns.
It can be useful if you have some writes that are really important so you want to be sure the stored values will reside on multiple machines. Also it might be necessary to use
when you customize [the read balance behavior](../../client-api/configuration/load-balance-and-failover.mdx#readbalancebehavior) and need to ensure the next request from the user 
will be able to read what he or she just wrote (the next open session might access a different node).

You can ask the server to wait until the replication is caught up with those particular changes.

* You can set a timeout (default: 15 seconds).
* You can specify whether you want to throw on timeout, which may happen in case of network issues (default: `true`).
* You can specify to how many replicas (nodes) the currently saved write must be replicated, before the `saveChanges` returns (default: 1).
* You can specify whether the `saveChanges()` will return only when the current write was replicated to majority of the nodes (default: `false`).

<TabItem value="saving_changes_4" label="saving_changes_4">
<CodeBlock language="js">
{`session.advanced
    .waitForReplicationAfterSaveChanges(\{
        throwOnTimeout: false, // default true
        timeout: 30000,
        replicas: 2, // minimum replicas to replicate
        majority: false
    \});

const employee = new Employee("John", "Doe");
await session.store(employee);
await session.saveChanges();
`}
</CodeBlock>
</TabItem>

<Admonition type="warning" title="Important" id="important" href="#important">
The `waitForReplicationAfterSaveChanges` waits only for replicas which are part of the cluster. It means that external replication destinations are not counted towards the number specified in `replicas` parameter, since they are not part of the cluster.
</Admonition>

<Admonition type="warning" title="Important" id="important" href="#important">

The usage of `waitForReplicationAfterSaveChanges` doesn't involve a distributed transaction (those are not supported since RavenDB 4.0). Even if RavenDB was not able
to write your changes to the number of replicas you specified, the data has been already written to some nodes. You will get an error but data is already there.

This is a powerful feature, but you need to be aware of the possible pitfalls of using it.

</Admonition>

 


